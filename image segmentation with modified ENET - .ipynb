{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66dd8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import torchinfo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6957f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "pin_memory = True\n",
    "\n",
    "train_img_dir = r'C:/Users/utkar/Desktop/ML/pytorch/image segmentation/SkinCancerDataset/train/images'\n",
    "train_mask_dir = r'C:/Users/utkar/Desktop/ML/pytorch/image segmentation/SkinCancerDataset/train/mask'\n",
    "val_img_dir = r'C:/Users/utkar/Desktop/ML/pytorch/image segmentation/SkinCancerDataset/test/images'\n",
    "val_mask_dir = r'C:/Users/utkar/Desktop/ML/pytorch/image segmentation/SkinCancerDataset/test/mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset source: https://www.kaggle.com/datasets/surajghuwalewala/ham1000-segmentation-and-classification\n",
    "\n",
    "class ISDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, img_transform, mask_transform):\n",
    "        super(ISDataset, self)\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_transform = img_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.img = os.listdir(img_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.img[index])\n",
    "        mask_path = os.path.join(self.mask_dir, self.img[index].replace('.jpg', '_mask.png'))\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        mask = np.array(Image.open(mask_path).convert('L'))\n",
    "        \n",
    "        img = self.img_transform(img)\n",
    "        mask = self.mask_transform(mask)\n",
    "            \n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Normalize([0, 0, 0], [1, 1, 1]),\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Normalize([0], [1]),\n",
    "])\n",
    "\n",
    "train_ds = ISDataset(\n",
    "    img_dir=train_img_dir,\n",
    "    mask_dir=train_mask_dir,\n",
    "    img_transform=img_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "\n",
    "val_ds = ISDataset(\n",
    "    img_dir=val_img_dir,\n",
    "    mask_dir=val_mask_dir,\n",
    "    img_transform=img_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=pin_memory,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=pin_memory,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(in_c, out_c, regular=False, dilated=False, dilation=None, asymm=False, down_sampling=False, up_sampling=False):\n",
    "    if down_sampling:\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, in_c//2, kernel_size=(2, 2), stride=2),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),  \n",
    "            nn.Conv2d(in_c//2, in_c//2, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_c//2, in_c*(out_c//in_c-1), kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(in_c*(out_c//in_c-1))\n",
    "        )\n",
    "        conv1 = nn.Sequential(nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), return_indices=True))\n",
    "        \n",
    "        return conv, conv1\n",
    "        \n",
    "    if up_sampling:\n",
    "        conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_c, in_c//2, kernel_size=(2, 2), stride=(2, 2)),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_c//2, in_c//2, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_c//2, out_c, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        conv1 = nn.Sequential(nn.MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2)))\n",
    "        return conv#, conv1\n",
    "        \n",
    "    elif regular:\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, in_c//2, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_c//2, in_c//2, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_c//2, out_c, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        return conv\n",
    "    elif dilated:\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, in_c//2, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_c//2, in_c//2, kernel_size=(3, 3), dilation=dilation, padding=dilation),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_c//2, out_c, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        return conv\n",
    "        \n",
    "    elif asymm:\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, in_c//2, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d (in_c//2, in_c//2, (1, 5), bias = False, padding=(0, 2)),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d (in_c//2, in_c//2, (5, 1), bias = False, padding=(2, 0)),\n",
    "            nn.BatchNorm2d(in_c//2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_c//2, out_c, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        return conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf01290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_c, out_c):\n",
    "    conv = nn.Sequential(nn.Conv2d(in_c, out_c, kernel_size=(1, 1)))\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ENET, self).__init__()\n",
    "        \n",
    "        self.initial1 = nn.Conv2d(3, 13, kernel_size=(3, 3), stride=2, padding=1)\n",
    "        self.initial2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.bn10_1, self.bn10_2 = bottleneck(16, 64, down_sampling=True)   ### 2\n",
    "        self.conv1x1_10 = conv1x1(64, 64)\n",
    "        self.bn11 = bottleneck(64, 64, regular=True)\n",
    "        self.conv1x1_11 = conv1x1(128, 64)\n",
    "        self.bn12 = bottleneck(64, 64, regular=True)\n",
    "        self.conv1x1_12 = conv1x1(128, 64)\n",
    "        self.bn13 = bottleneck(64, 64, regular=True)\n",
    "        self.conv1x1_13 = conv1x1(128, 64)\n",
    "        self.bn14 = bottleneck(64, 64, regular=True)\n",
    "        self.conv1x1_14 = conv1x1(128, 64)\n",
    "        \n",
    "        self.bn20_1, self.bn20_2 = bottleneck(64, 128, down_sampling=True)  ### 2\n",
    "        self.conv1x1_20 = conv1x1(128, 128)\n",
    "        self.bn21 = bottleneck(128, 128, regular=True)\n",
    "        self.conv1x1_21 = conv1x1(256, 128)\n",
    "        self.bn22 = bottleneck(128, 128, dilated=True, dilation=2)\n",
    "        self.conv1x1_22 = conv1x1(256, 128)\n",
    "        self.bn23 = bottleneck(128, 128, asymm=True)\n",
    "        self.conv1x1_23 = conv1x1(256, 128)\n",
    "        self.bn24 = bottleneck(128, 128, dilated=True, dilation=4)\n",
    "        self.conv1x1_24 = conv1x1(256, 128)\n",
    "        self.bn25 = bottleneck(128, 128, regular=True)\n",
    "        self.conv1x1_25 = conv1x1(256, 128)\n",
    "        self.bn26 = bottleneck(128, 128, dilated=True, dilation=8)\n",
    "        self.conv1x1_26 = conv1x1(256, 128)\n",
    "        self.bn27 = bottleneck(128, 128, asymm=True)\n",
    "        self.conv1x1_27 = conv1x1(256, 128)\n",
    "        self.bn28 = bottleneck(128, 128, dilated=True, dilation=8)\n",
    "        self.conv1x1_28 = conv1x1(256, 128)\n",
    "\n",
    "        self.bn31 = bottleneck(128, 128, regular=True)\n",
    "        self.conv1x1_31 = conv1x1(256, 128)\n",
    "        self.bn32 = bottleneck(128, 128, dilated=True, dilation=2)\n",
    "        self.conv1x1_32 = conv1x1(256, 128)\n",
    "        self.bn33 = bottleneck(128, 128, asymm=True)\n",
    "        self.conv1x1_33 = conv1x1(256, 128)\n",
    "        self.bn34 = bottleneck(128, 128, dilated=True, dilation=4)\n",
    "        self.conv1x1_34 = conv1x1(256, 128)\n",
    "        self.bn35 = bottleneck(128, 128, regular=True)\n",
    "        self.conv1x1_35 = conv1x1(256, 128)\n",
    "        self.bn36 = bottleneck(128, 128, dilated=True, dilation=8)\n",
    "        self.conv1x1_36 = conv1x1(256, 128)\n",
    "        self.bn37 = bottleneck(128, 128, asymm=True)\n",
    "        self.conv1x1_37 = conv1x1(256, 128)\n",
    "        self.bn38 = bottleneck(128, 128, dilated=True, dilation=8)\n",
    "        self.conv1x1_38 = conv1x1(256, 128)\n",
    "        \n",
    "        self.bn40_1 = bottleneck(128, 64, up_sampling=True) # , self.bn40_2\n",
    "        self.conv1x1_40 = conv1x1(64, 64)\n",
    "        self.bn41 = bottleneck(64, 64, regular=True)\n",
    "        self.conv1x1_41 = conv1x1(128, 64)\n",
    "        self.bn42 = bottleneck(64, 64, regular=True)\n",
    "        self.conv1x1_42 = conv1x1(128, 64)\n",
    "        \n",
    "        self.bn50_1 = bottleneck(64, 16, up_sampling=True) # , self.bn50_2\n",
    "        self.conv1x1_50 = conv1x1(16, 16)\n",
    "        self.bn51 = bottleneck(16, 16, regular=True)\n",
    "        self.conv1x1_51 = conv1x1(32, 16)\n",
    "        \n",
    "        self.out = nn.ConvTranspose2d(16, 1, kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "    def forward(self, img):\n",
    "        x_i1 = self.initial1(img)\n",
    "        x_i2 = self.initial2(img)\n",
    "        #print(x_i1.shape, x_i2.shape)\n",
    "        x_i = torch.concat([x_i1, x_i2], 1)\n",
    "        \n",
    "        x10_1 = self.bn10_1(x_i)\n",
    "        x10_2, indices_10 = self.bn10_2(x_i)      # maxpooling\n",
    "        #print(x10_2.shape, indices_10.shape)\n",
    "        x10 = self.conv1x1_10(torch.concat([x10_1, x10_2], 1))\n",
    "        x = self.bn11(x10)\n",
    "        x11 = self.conv1x1_11(torch.concat([x, x10], 1))\n",
    "        x = self.bn12(x11)\n",
    "        x12 = self.conv1x1_12(torch.concat([x, x11], 1))\n",
    "        x = self.bn13(x12)\n",
    "        x13 = self.conv1x1_13(torch.concat([x, x12], 1))\n",
    "        x = self.bn14(x13)\n",
    "        x14 = self.conv1x1_14(torch.concat([x, x13], 1))\n",
    "        \n",
    "        x20_1 = self.bn20_1(x14)\n",
    "        x20_2, indices_20 = self.bn20_2(x14)     # maxpooling\n",
    "        #print(indices_20.shape)\n",
    "        x20 = self.conv1x1_20(torch.concat([x20_1, x20_2], 1))\n",
    "        x = self.bn21(x20)\n",
    "        x21 = self.conv1x1_21(torch.concat([x, x20], 1))\n",
    "        x = self.bn22(x21)\n",
    "        #print(x.shape, x21.shape)\n",
    "        x22 = self.conv1x1_22(torch.concat([x, x21], 1))\n",
    "        x = self.bn23(x22)\n",
    "        #print(x.shape, x22.shape)\n",
    "        x23 = self.conv1x1_23(torch.concat([x, x22], 1))\n",
    "        x = self.bn24(x23)\n",
    "        x24 = self.conv1x1_24(torch.concat([x, x23], 1))\n",
    "        x = self.bn25(x24)\n",
    "        x25 = self.conv1x1_25(torch.concat([x, x24], 1))\n",
    "        x = self.bn26(x25)\n",
    "        x26 = self.conv1x1_26(torch.concat([x, x25], 1))\n",
    "        x = self.bn27(x26)\n",
    "        x27 = self.conv1x1_27(torch.concat([x, x26], 1))\n",
    "        x = self.bn28(x27)\n",
    "        x28 = self.conv1x1_28(torch.concat([x, x27], 1))\n",
    "        \n",
    "        x = self.bn31(x28)\n",
    "        x31 = self.conv1x1_31(torch.concat([x, x28], 1))\n",
    "        x = self.bn32(x31)\n",
    "        x32 = self.conv1x1_32(torch.concat([x, x31], 1))\n",
    "        x = self.bn33(x32)\n",
    "        x33 = self.conv1x1_33(torch.concat([x, x32], 1))\n",
    "        x = self.bn34(x33)\n",
    "        x34 = self.conv1x1_34(torch.concat([x, x33], 1))\n",
    "        x = self.bn35(x34)\n",
    "        x35 = self.conv1x1_35(torch.concat([x, x34], 1))\n",
    "        x = self.bn36(x35)\n",
    "        x36 = self.conv1x1_36(torch.concat([x, x35], 1))\n",
    "        x = self.bn37(x36)\n",
    "        x37 = self.conv1x1_37(torch.concat([x, x36], 1))\n",
    "        x = self.bn38(x37)\n",
    "        x38 = self.conv1x1_38(torch.concat([x, x37], 1))\n",
    "        \n",
    "        x40_1 = self.bn40_1(x38)\n",
    "        #print(x40_1.shape)\n",
    "        x40_1 = self.conv1x1_40(x40_1)\n",
    "        #print(indices_20)\n",
    "        #x40_2 = self.bn40_2(x38)   # add x38\n",
    "        #x40 = self.conv1x1_40(torch.concat([x40_1, x40_2], 1))\n",
    "        x = self.bn41(x40_1)\n",
    "        x41 = self.conv1x1_41(torch.concat([x, x40_1], 1))\n",
    "        x = self.bn42(x41)\n",
    "        x42 = self.conv1x1_42(torch.concat([x, x41], 1))\n",
    "        \n",
    "        x50_1 = self.bn50_1(x42)\n",
    "        #print(x50_1.shape, x42.shape)\n",
    "        x50_1 = self.conv1x1_50(x50_1)\n",
    "        #print(x50_1.shape)\n",
    "        #x50_2 = self.bn50_2(x42)\n",
    "        #x50 = self.conv1x1_50(torch.concat([x50_1, x50_2], 1))\n",
    "        x = self.bn51(x50_1)\n",
    "        x51 = self.conv1x1_51(torch.concat([x, x50_1], 1))\n",
    "        \n",
    "        x_out = self.out(x51)\n",
    "        return x_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c736b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ENET()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656d27d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(torchinfo.summary(model, input_size=(1, 3, 256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 3, 512, 512))\n",
    "y = model(x.to(device))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfcaedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_acc(loader, model, device='cuda'):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)   # returns product of the values in tensor\n",
    "            dice_score += (2*(preds*y).sum())/((preds + y).sum()+1e-8)\n",
    "            \n",
    "    print(\n",
    "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
    "    )\n",
    "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
    "    model.train()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2edecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()   # to avoid vanishing gradient problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb82f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    loop = tqdm(train_loader)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device)\n",
    "        target = targets.float().to(device)\n",
    "        \n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, target)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        # checcking accuracy\n",
    "        check_acc(val_loader, model, device=device)\n",
    "    print(f'epoch {epoch}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cdd386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872b368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = np.random.randint(442, 443)\n",
    "print(b)\n",
    "for img, mask in val_ds:\n",
    "    a += 1\n",
    "    if a == b:\n",
    "        img1 = img.unsqueeze(0).to(device)\n",
    "        #rint(img1.shape)\n",
    "        mask_m = model(img1)\n",
    "        #rint(mask_m.shape)\n",
    "        print('target')\n",
    "        plt.imshow(mask.permute(1, 2, 0), cmap='gray')\n",
    "        plt.show()\n",
    "        mask_m = torch.squeeze(mask_m)\n",
    "        print(mask_m.shape)\n",
    "        mask_m = mask_m.unsqueeze(1).permute(0, 2, 1).cpu().detach().numpy()\n",
    "        print('predicted')\n",
    "        plt.imshow(mask_m, cmap='gray')\n",
    "        plt.show()\n",
    "        print('image')\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "        plt.show()\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
